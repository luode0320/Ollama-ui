<h1 align="center">
  Ollama LLMsåŠŸèƒ½é½å…¨ä¸”ç¾è§‚çš„Webç•Œé¢
</h1>

<div align="center">
  
![demo.png](public%2Fdemo.png)
  
</div>


å¯åŠ¨å¹¶è¿è¡Œå¤§å‹è¯­è¨€æ¨¡å‹ **è¿…é€Ÿ**, **æœ¬åœ°** ç”šè‡³ **ç¦»çº¿**.
è¿™ä¸ªé¡¹ç›®æ—¨åœ¨æˆä¸ºä½ å¼€å§‹ä½¿ç”¨LLMçš„æœ€ç®€å•æ–¹æ³•ã€‚ ä¸éœ€è¦ç¹çå’Œçƒ¦äººçš„è®¾ç½®ï¼

# å…ˆå†³æ¡ä»¶ âš™ï¸

è¦ä½¿ç”¨ Web ç•Œé¢ï¼Œå¿…é¡»æ»¡è¶³ä»¥ä¸‹è¦æ±‚ï¼š

1. ä¸‹è½½ [Ollama](https://ollama.com/download) å¹¶è®©å®ƒè¿è¡Œã€‚æˆ–è€…åœ¨ Docker å®¹å™¨ä¸­è¿è¡Œå®ƒ. é€‰ä¸­ [docs](https://github.com/ollama/ollama) æœ‰å…³è¯´æ˜.
2. Node.js (18+) and npm æ˜¯å¿…éœ€çš„. [Download](https://nodejs.org/en/download)

# å®‰è£…ä»¥åœ¨æœ¬åœ°è¿è¡Œ ğŸ“–

**1. é‡å‘½å `.example.env` to `.env`:** 

```
mv .example.env .env
```

**2. å¦‚æœæ‚¨çš„ Ollama å®ä¾‹æœªåœ¨é»˜è®¤ IP åœ°å€å’Œç«¯å£ä¸Šè¿è¡Œï¼Œè¯·æ›´æ”¹ .env æ–‡ä»¶ä¸­çš„å˜é‡ä»¥é€‚åˆæ‚¨çš„ç”¨ä¾‹:**

```
NEXT_PUBLIC_OLLAMA_URL="http://localhost:11434"
```

**3. å®‰è£…ä¾èµ–é¡¹:**

```
npm install
```

**4. å¯åŠ¨:**

```
npm run build
npm run dev
```

**5. è½¬åˆ° [localhost:3000](http://localhost:3000) å¹¶å¼€å§‹ä¸æ‚¨æœ€å–œæ¬¢çš„æ¨¡ç‰¹èŠå¤©!**

# dockerç›¸å…³éƒ¨ç½²

# Ollamaæ˜¯ä»€ä¹ˆ?

Ollama ä¸æ˜¯ä¸€ä¸ªå¤§è¯­è¨€æ¨¡å‹, å®ƒåªæ˜¯ä¸€ä¸ªå…è®¸å¤§æ¨¡å‹çš„è„šæ‰‹æ¶ã€‚

Ollama æ˜¯ä¸€ä¸ªå¼ºå¤§çš„æ¡†æ¶ï¼Œè®¾è®¡ç”¨äºåœ¨ Docker å®¹å™¨ä¸­éƒ¨ç½² LLMã€‚

Ollama çš„ä¸»è¦åŠŸèƒ½æ˜¯åœ¨ Docker å®¹å™¨å†…éƒ¨ç½²å’Œç®¡ç† LLM çš„ä¿ƒè¿›è€…ï¼Œå®ƒä½¿è¯¥è¿‡ç¨‹å˜å¾—éå¸¸ç®€å•ã€‚

å®ƒå¸®åŠ©ç”¨æˆ·å¿«é€Ÿåœ¨æœ¬åœ°è¿è¡Œå¤§æ¨¡å‹ï¼Œé€šè¿‡ç®€å•çš„å®‰è£…æŒ‡ä»¤ï¼Œå¯ä»¥è®©ç”¨æˆ·æ‰§è¡Œä¸€æ¡å‘½ä»¤å°±åœ¨æœ¬åœ°è¿è¡Œå¼€æºå¤§å‹è¯­è¨€æ¨¡å‹ã€‚



## Ollamaæœ‰ä¸¤ç§æ¨¡å¼

- CPUæ¨¡å¼
- GPUæ˜¾å¡æ¨¡å¼

> è¿™é‡Œä½¿ç”¨çš„æ˜¯CPUæ¨¡å¼, GPUæ¨¡å¼è¯·è‡ªè¡Œç™¾åº¦



## å®‰è£…

```sh
docker pull luode0320/ollama:latest
```



## å¯åŠ¨

- å¯åŠ¨ååªæ˜¯å¯åŠ¨äº†ä¸€ä¸ªè„šæ‰‹æ¶, å¹¶æ²¡æœ‰å¯ç”¨ä»»ä½•çš„æ¨¡å‹
- éœ€è¦æˆ‘ä»¬è¿›å…¥ollamaåå®‰è£…æˆ‘ä»¬éœ€è¦çš„å¤§æ¨¡å‹

```sh
docker run -d \
--restart=always  \
-p 11434:11434 \
--name ollama \
-v /usr/local/src/ollama:/root/.ollama \
--name ollama \
luode0320/ollama:latest
```

```sh
docker exec -it ollama ollama --version
# ollama version is 0.1.38
```



# å®‰è£…æ¨¡å‹

3Bæ¨¡å‹éœ€è¦8Gå†…å­˜ï¼Œ7B è‡³å°‘éœ€è¦ 8GB å†…å­˜ï¼Œè¿è¡Œ 13B è‡³å°‘éœ€è¦ 16GB å†…å­˜ã€‚

[æ¨¡å‹ä»“åº“](https://ollama.com/library)

- ä¸‹é¢çš„å‘½ä»¤å°±æ˜¯å…è®¸å¤§æ¨¡å‹äº†, å¦‚æœæ²¡æœ‰ä¸‹è½½ä¼šå…ˆä¸‹è½½

```
docker exec -it ollama ollama run gemma:2b
```

```sh
[root@luode ~]# docker exec -it ollama ollama run gemma:2b
success
>>> ä½ å¥½
ä½ å¥½ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ
```

- å…¶ä»–å‘½ä»¤

```sh
docker exec -it ollama ollama list # æŸ¥çœ‹å®‰è£…çš„æ¨¡å‹
docker exec -it ollama ollama rm <name> # åˆ é™¤æ¨¡å‹
```



# å®‰è£…ollama-ui

```sh
docker pull luode0320/ollama-ui:latest
```



## å¯åŠ¨

```sh
docker run -d \
-p 6001:3000 \
--restart=always  \
--name ollama-ui \
-v /etc/hosts:/etc/hosts \
-e NEXT_PUBLIC_OLLAMA_URL="http://0.0.0.0:11434" \
luode0320/ollama-ui:latest
```

